{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# åµŒå…¥æ•°æ®è¯¦ç»†åˆ†æ - ç†è§£å”¯ä¸€å€¼æ•°é‡\n",
                "\n",
                "æœ¬ç¬”è®°æœ¬ä¸“é—¨è§£ç­”ï¼šä¸ºä»€ä¹ˆ embedding ç»´åº¦çš„å”¯ä¸€å€¼æ•°é‡ä¼šå°‘äº movie_id æ•°é‡ï¼Ÿ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('default')\n",
                "sns.set_palette(\"husl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# è¯»å–æ•°æ®\n",
                "data_dir = Path('.')\n",
                "df_image = pd.read_parquet(data_dir / 'image_embeddings_50d.parquet')\n",
                "df_text = pd.read_parquet(data_dir / 'text_embeddings_50d.parquet')\n",
                "\n",
                "print(f\"å›¾åƒåµŒå…¥æ•°æ®å½¢çŠ¶: {df_image.shape}\")\n",
                "print(f\"æ–‡æœ¬åµŒå…¥æ•°æ®å½¢çŠ¶: {df_text.shape}\")\n",
                "print(f\"\\nå›¾åƒæ•°æ®åˆ—: {list(df_image.columns[:5])}...\")\n",
                "print(f\"æ–‡æœ¬æ•°æ®åˆ—: {list(df_text.columns[:5])}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ç†è§£\"å”¯ä¸€å€¼æ•°é‡\"çš„å«ä¹‰\n",
                "\n",
                "**å…³é”®ç‚¹**ï¼š`nunique()` ç»Ÿè®¡çš„æ˜¯**å•ä¸ªåˆ—**ä¸­æœ‰å¤šå°‘ä¸ªä¸åŒçš„å€¼ï¼Œè€Œä¸æ˜¯æ•´ä¸ªåµŒå…¥å‘é‡çš„å”¯ä¸€æ€§ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ£€æŸ¥ movie_id çš„å”¯ä¸€æ€§\n",
                "print(\"=\" * 80)\n",
                "print(\"Movie ID åˆ†æ\")\n",
                "print(\"=\" * 80)\n",
                "print(f\"\\nå›¾åƒæ•°æ®:\")\n",
                "print(f\"  æ€»è¡Œæ•°: {len(df_image)}\")\n",
                "print(f\"  å”¯ä¸€ movie_id æ•°é‡: {df_image['movie_id'].nunique()}\")\n",
                "print(f\"  æ˜¯å¦æœ‰é‡å¤: {df_image['movie_id'].duplicated().any()}\")\n",
                "\n",
                "print(f\"\\næ–‡æœ¬æ•°æ®:\")\n",
                "print(f\"  æ€»è¡Œæ•°: {len(df_text)}\")\n",
                "print(f\"  å”¯ä¸€ movie_id æ•°é‡: {df_text['movie_id'].nunique()}\")\n",
                "print(f\"  æ˜¯å¦æœ‰é‡å¤: {df_text['movie_id'].duplicated().any()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. æ£€æŸ¥æ•´ä¸ªåµŒå…¥å‘é‡çš„å”¯ä¸€æ€§\n",
                "\n",
                "ç°åœ¨è®©æˆ‘ä»¬æ£€æŸ¥**å®Œæ•´çš„åµŒå…¥å‘é‡**ï¼ˆæ‰€æœ‰50ç»´ç»„åˆï¼‰æ˜¯å¦å”¯ä¸€ï¼š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def check_embedding_uniqueness(df, name):\n",
                "    \"\"\"æ£€æŸ¥åµŒå…¥å‘é‡çš„å”¯ä¸€æ€§\"\"\"\n",
                "    print(\"=\" * 80)\n",
                "    print(f\"{name} - åµŒå…¥å‘é‡å”¯ä¸€æ€§åˆ†æ\")\n",
                "    print(\"=\" * 80)\n",
                "    \n",
                "    # è·å–æ‰€æœ‰åµŒå…¥ç»´åº¦åˆ—\n",
                "    emb_cols = [col for col in df.columns if col.startswith('emb_')]\n",
                "    print(f\"\\nåµŒå…¥ç»´åº¦æ•°: {len(emb_cols)}\")\n",
                "    \n",
                "    # æå–åµŒå…¥çŸ©é˜µ\n",
                "    embeddings = df[emb_cols].values\n",
                "    print(f\"åµŒå…¥çŸ©é˜µå½¢çŠ¶: {embeddings.shape}\")\n",
                "    \n",
                "    # æ–¹æ³•1: ä½¿ç”¨ pandas çš„ drop_duplicates æ£€æŸ¥\n",
                "    unique_embeddings = df[emb_cols].drop_duplicates()\n",
                "    print(f\"\\nå”¯ä¸€åµŒå…¥å‘é‡æ•°é‡: {len(unique_embeddings)}\")\n",
                "    print(f\"æ€»åµŒå…¥å‘é‡æ•°é‡: {len(df)}\")\n",
                "    print(f\"é‡å¤çš„åµŒå…¥å‘é‡æ•°é‡: {len(df) - len(unique_embeddings)}\")\n",
                "    \n",
                "    if len(df) == len(unique_embeddings):\n",
                "        print(\"\\nâœ… æ¯ä¸ªç”µå½±éƒ½æœ‰å”¯ä¸€çš„åµŒå…¥å‘é‡ï¼\")\n",
                "    else:\n",
                "        print(f\"\\nâš ï¸  æœ‰ {len(df) - len(unique_embeddings)} ä¸ªé‡å¤çš„åµŒå…¥å‘é‡\")\n",
                "        \n",
                "        # æ‰¾å‡ºé‡å¤çš„åµŒå…¥\n",
                "        duplicated_mask = df[emb_cols].duplicated(keep=False)\n",
                "        duplicated_movies = df[duplicated_mask]['movie_id'].values\n",
                "        print(f\"   æ¶‰åŠçš„ movie_id: {duplicated_movies[:10]}...\" if len(duplicated_movies) > 10 else f\"   æ¶‰åŠçš„ movie_id: {duplicated_movies}\")\n",
                "    \n",
                "    return embeddings, emb_cols\n",
                "\n",
                "# æ£€æŸ¥å›¾åƒåµŒå…¥\n",
                "image_embeddings, image_emb_cols = check_embedding_uniqueness(df_image, \"å›¾åƒåµŒå…¥\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ£€æŸ¥æ–‡æœ¬åµŒå…¥\n",
                "text_embeddings, text_emb_cols = check_embedding_uniqueness(df_text, \"æ–‡æœ¬åµŒå…¥\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ä¸ºä»€ä¹ˆå•ä¸ªç»´åº¦çš„å”¯ä¸€å€¼ä¼šå°‘ï¼Ÿ\n",
                "\n",
                "è®©æˆ‘ä»¬æ·±å…¥åˆ†æï¼š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"å•ä¸ªç»´åº¦å”¯ä¸€å€¼åˆ†æ\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# ç»Ÿè®¡æ¯ä¸ªç»´åº¦çš„å”¯ä¸€å€¼æ•°é‡\n",
                "unique_counts_image = [df_image[col].nunique() for col in image_emb_cols]\n",
                "unique_counts_text = [df_text[col].nunique() for col in text_emb_cols]\n",
                "\n",
                "print(f\"\\nå›¾åƒåµŒå…¥ - å„ç»´åº¦å”¯ä¸€å€¼ç»Ÿè®¡:\")\n",
                "print(f\"  æœ€å°å€¼: {min(unique_counts_image)}\")\n",
                "print(f\"  æœ€å¤§å€¼: {max(unique_counts_image)}\")\n",
                "print(f\"  å¹³å‡å€¼: {np.mean(unique_counts_image):.2f}\")\n",
                "print(f\"  ä¸­ä½æ•°: {np.median(unique_counts_image):.2f}\")\n",
                "\n",
                "print(f\"\\næ–‡æœ¬åµŒå…¥ - å„ç»´åº¦å”¯ä¸€å€¼ç»Ÿè®¡:\")\n",
                "print(f\"  æœ€å°å€¼: {min(unique_counts_text)}\")\n",
                "print(f\"  æœ€å¤§å€¼: {max(unique_counts_text)}\")\n",
                "print(f\"  å¹³å‡å€¼: {np.mean(unique_counts_text):.2f}\")\n",
                "print(f\"  ä¸­ä½æ•°: {np.median(unique_counts_text):.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å¯è§†åŒ–æ¯ä¸ªç»´åº¦çš„å”¯ä¸€å€¼æ•°é‡\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "axes[0].bar(range(len(unique_counts_image)), unique_counts_image, alpha=0.7)\n",
                "axes[0].axhline(y=len(df_image), color='r', linestyle='--', label=f'æ€»æ ·æœ¬æ•° ({len(df_image)})')\n",
                "axes[0].set_title('å›¾åƒåµŒå…¥ - å„ç»´åº¦å”¯ä¸€å€¼æ•°é‡', fontsize=12, fontweight='bold')\n",
                "axes[0].set_xlabel('ç»´åº¦ç´¢å¼•')\n",
                "axes[0].set_ylabel('å”¯ä¸€å€¼æ•°é‡')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "axes[1].bar(range(len(unique_counts_text)), unique_counts_text, alpha=0.7, color='orange')\n",
                "axes[1].axhline(y=len(df_text), color='r', linestyle='--', label=f'æ€»æ ·æœ¬æ•° ({len(df_text)})')\n",
                "axes[1].set_title('æ–‡æœ¬åµŒå…¥ - å„ç»´åº¦å”¯ä¸€å€¼æ•°é‡', fontsize=12, fontweight='bold')\n",
                "axes[1].set_xlabel('ç»´åº¦ç´¢å¼•')\n",
                "axes[1].set_ylabel('å”¯ä¸€å€¼æ•°é‡')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°å€¼ç¢°æ’\n",
                "\n",
                "å•ä¸ªç»´åº¦çš„å”¯ä¸€å€¼å°‘äºæ ·æœ¬æ•°ï¼Œå¯èƒ½çš„åŸå› ï¼š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ£€æŸ¥æŸä¸ªç»´åº¦çš„å€¼åˆ†å¸ƒ\n",
                "example_dim = 'emb_0'\n",
                "\n",
                "print(f\"ä»¥ {example_dim} ä¸ºä¾‹åˆ†æ:\\n\")\n",
                "print(f\"å›¾åƒåµŒå…¥:\")\n",
                "print(f\"  æ€»æ ·æœ¬æ•°: {len(df_image)}\")\n",
                "print(f\"  {example_dim} å”¯ä¸€å€¼æ•°é‡: {df_image[example_dim].nunique()}\")\n",
                "print(f\"  å·®å€¼: {len(df_image) - df_image[example_dim].nunique()}\")\n",
                "\n",
                "# æŸ¥çœ‹å€¼çš„åˆ†å¸ƒ\n",
                "value_counts = df_image[example_dim].value_counts()\n",
                "duplicated_values = value_counts[value_counts > 1]\n",
                "\n",
                "print(f\"\\n  æœ‰ {len(duplicated_values)} ä¸ªå€¼å‡ºç°äº†å¤šæ¬¡\")\n",
                "if len(duplicated_values) > 0:\n",
                "    print(f\"  å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼:\")\n",
                "    for val, count in duplicated_values.head(5).items():\n",
                "        print(f\"    {val:.6f}: å‡ºç° {count} æ¬¡\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. åŸå› è§£é‡Š\n",
                "\n",
                "### ğŸ¯ æ ¸å¿ƒè§£ç­”ï¼š\n",
                "\n",
                "**å•ä¸ªç»´åº¦çš„å”¯ä¸€å€¼å°‘äºæ ·æœ¬æ•°æ˜¯æ­£å¸¸çš„ï¼**\n",
                "\n",
                "åŸå› å¦‚ä¸‹ï¼š\n",
                "\n",
                "1. **æ•°å€¼ç¢°æ’ï¼ˆNumerical Collisionï¼‰**ï¼š\n",
                "   - æµ®ç‚¹æ•°ç²¾åº¦æœ‰é™ï¼ˆfloat32ï¼‰\n",
                "   - ä¸åŒç”µå½±åœ¨æŸä¸ªç‰¹å®šç»´åº¦ä¸Šå¯èƒ½æ°å¥½æœ‰ç›¸åŒæˆ–éå¸¸æ¥è¿‘çš„å€¼\n",
                "   - è¿™æ˜¯è¿ç»­å€¼ç©ºé—´ä¸­çš„æ­£å¸¸ç°è±¡\n",
                "\n",
                "2. **åµŒå…¥çš„æœ¬è´¨**ï¼š\n",
                "   - åµŒå…¥å‘é‡çš„**æ•´ä½“ç»„åˆ**æ‰æ˜¯å”¯ä¸€çš„\n",
                "   - å•ä¸ªç»´åº¦åªæ˜¯æ•´ä½“çš„ä¸€ä¸ªåˆ†é‡\n",
                "   - å°±åƒåæ ‡ç³»ä¸­ï¼Œä¸åŒç‚¹å¯ä»¥æœ‰ç›¸åŒçš„ x åæ ‡ï¼Œä½† (x,y) ç»„åˆæ˜¯å”¯ä¸€çš„\n",
                "\n",
                "3. **å¤šæ ·æ€§ä½“ç°åœ¨æ•´ä½“**ï¼š\n",
                "   - 50ç»´ç©ºé—´ä¸­ï¼Œå³ä½¿æ¯ä¸ªç»´åº¦åªæœ‰100ä¸ªä¸åŒå€¼\n",
                "   - ç†è®ºä¸Šå¯ä»¥è¡¨ç¤º 100^50 ç§ä¸åŒçš„ç»„åˆ\n",
                "   - è¿œè¶…è¿‡3882ä¸ªç”µå½±çš„éœ€æ±‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# éªŒè¯ï¼šè®¡ç®—ç†è®ºç»„åˆç©ºé—´\n",
                "print(\"=\" * 80)\n",
                "print(\"ç†è®ºç»„åˆç©ºé—´åˆ†æ\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "avg_unique_per_dim_image = np.mean(unique_counts_image)\n",
                "avg_unique_per_dim_text = np.mean(unique_counts_text)\n",
                "\n",
                "print(f\"\\nå›¾åƒåµŒå…¥:\")\n",
                "print(f\"  å¹³å‡æ¯ç»´å”¯ä¸€å€¼: {avg_unique_per_dim_image:.0f}\")\n",
                "print(f\"  ç»´åº¦æ•°: {len(image_emb_cols)}\")\n",
                "print(f\"  ç†è®ºç»„åˆæ•°: {avg_unique_per_dim_image:.0f}^{len(image_emb_cols)} (å¤©æ–‡æ•°å­—)\")\n",
                "print(f\"  å®é™…éœ€è¦è¡¨ç¤º: {len(df_image)} ä¸ªç”µå½±\")\n",
                "print(f\"  âœ… ç©ºé—´å……è¶³åº¦: æå…¶å……è¶³\")\n",
                "\n",
                "print(f\"\\næ–‡æœ¬åµŒå…¥:\")\n",
                "print(f\"  å¹³å‡æ¯ç»´å”¯ä¸€å€¼: {avg_unique_per_dim_text:.0f}\")\n",
                "print(f\"  ç»´åº¦æ•°: {len(text_emb_cols)}\")\n",
                "print(f\"  ç†è®ºç»„åˆæ•°: {avg_unique_per_dim_text:.0f}^{len(text_emb_cols)} (å¤©æ–‡æ•°å­—)\")\n",
                "print(f\"  å®é™…éœ€è¦è¡¨ç¤º: {len(df_text)} ä¸ªç”µå½±\")\n",
                "print(f\"  âœ… ç©ºé—´å……è¶³åº¦: æå…¶å……è¶³\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. éªŒè¯åµŒå…¥å‘é‡çš„å®é™…å¤šæ ·æ€§"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# è®¡ç®—åµŒå…¥å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "def analyze_embedding_diversity(embeddings, name, sample_size=500):\n",
                "    \"\"\"åˆ†æåµŒå…¥å‘é‡çš„å¤šæ ·æ€§\"\"\"\n",
                "    print(\"=\" * 80)\n",
                "    print(f\"{name} - å¤šæ ·æ€§åˆ†æ\")\n",
                "    print(\"=\" * 80)\n",
                "    \n",
                "    # éšæœºé‡‡æ ·ä»¥åŠ å¿«è®¡ç®—\n",
                "    if len(embeddings) > sample_size:\n",
                "        indices = np.random.choice(len(embeddings), sample_size, replace=False)\n",
                "        sample_embeddings = embeddings[indices]\n",
                "        print(f\"\\nä½¿ç”¨ {sample_size} ä¸ªæ ·æœ¬è¿›è¡Œåˆ†æ\")\n",
                "    else:\n",
                "        sample_embeddings = embeddings\n",
                "        print(f\"\\nä½¿ç”¨å…¨éƒ¨ {len(embeddings)} ä¸ªæ ·æœ¬\")\n",
                "    \n",
                "    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ\n",
                "    similarity_matrix = cosine_similarity(sample_embeddings)\n",
                "    \n",
                "    # è·å–ä¸Šä¸‰è§’ï¼ˆæ’é™¤å¯¹è§’çº¿ï¼‰\n",
                "    mask = np.triu(np.ones_like(similarity_matrix, dtype=bool), k=1)\n",
                "    similarities = similarity_matrix[mask]\n",
                "    \n",
                "    print(f\"\\nç›¸ä¼¼åº¦ç»Ÿè®¡:\")\n",
                "    print(f\"  å‡å€¼: {similarities.mean():.4f}\")\n",
                "    print(f\"  æ ‡å‡†å·®: {similarities.std():.4f}\")\n",
                "    print(f\"  æœ€å°å€¼: {similarities.min():.4f}\")\n",
                "    print(f\"  æœ€å¤§å€¼: {similarities.max():.4f}\")\n",
                "    print(f\"  ä¸­ä½æ•°: {np.median(similarities):.4f}\")\n",
                "    \n",
                "    # ç»˜åˆ¶ç›¸ä¼¼åº¦åˆ†å¸ƒ\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.hist(similarities, bins=50, edgecolor='black', alpha=0.7)\n",
                "    plt.axvline(similarities.mean(), color='r', linestyle='--', linewidth=2, label=f'å‡å€¼: {similarities.mean():.4f}')\n",
                "    plt.title(f'{name} - åµŒå…¥å‘é‡ä½™å¼¦ç›¸ä¼¼åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
                "    plt.xlabel('ä½™å¼¦ç›¸ä¼¼åº¦')\n",
                "    plt.ylabel('é¢‘æ•°')\n",
                "    plt.legend()\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    if similarities.mean() < 0.5:\n",
                "        print(\"\\nâœ… åµŒå…¥å‘é‡å…·æœ‰è‰¯å¥½çš„å¤šæ ·æ€§ï¼ˆä½ç›¸ä¼¼åº¦ï¼‰\")\n",
                "    elif similarities.mean() < 0.8:\n",
                "        print(\"\\nâš ï¸  åµŒå…¥å‘é‡æœ‰ä¸€å®šç›¸ä¼¼æ€§ï¼Œä½†ä»æœ‰åŒºåˆ†åº¦\")\n",
                "    else:\n",
                "        print(\"\\nâŒ åµŒå…¥å‘é‡ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œå¤šæ ·æ€§ä¸è¶³\")\n",
                "\n",
                "# åˆ†æå›¾åƒåµŒå…¥\n",
                "analyze_embedding_diversity(image_embeddings, \"å›¾åƒåµŒå…¥\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ†ææ–‡æœ¬åµŒå…¥\n",
                "analyze_embedding_diversity(text_embeddings, \"æ–‡æœ¬åµŒå…¥\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. æ€»ç»“\n",
                "\n",
                "### ğŸ“Œ å…³é”®ç»“è®ºï¼š\n",
                "\n",
                "1. **å•ä¸ªç»´åº¦çš„å”¯ä¸€å€¼å°‘æ˜¯æ­£å¸¸çš„**\n",
                "   - è¿™ä¸ä»£è¡¨åµŒå…¥ç¼ºä¹å¤šæ ·æ€§\n",
                "   - å¤šæ ·æ€§ä½“ç°åœ¨50ç»´çš„ç»„åˆç©ºé—´ä¸­\n",
                "\n",
                "2. **æ•´ä½“åµŒå…¥å‘é‡æ˜¯å”¯ä¸€çš„**\n",
                "   - æ¯ä¸ªç”µå½±éƒ½æœ‰ç‹¬ç‰¹çš„50ç»´å‘é‡\n",
                "   - å³ä½¿å•ä¸ªç»´åº¦æœ‰é‡å¤å€¼\n",
                "\n",
                "3. **ç±»æ¯”ç†è§£**ï¼š\n",
                "   - å°±åƒåœ°çƒä¸Šçš„äººï¼Œå¯èƒ½æœ‰ç›¸åŒçš„èº«é«˜ï¼ˆå•ä¸ªç»´åº¦ï¼‰\n",
                "   - ä½†èº«é«˜+ä½“é‡+å¹´é¾„+...çš„ç»„åˆæ˜¯å”¯ä¸€çš„\n",
                "\n",
                "4. **æ•°å­¦è§’åº¦**ï¼š\n",
                "   - 3873^50 >> 3882\n",
                "   - è¡¨ç¤ºç©ºé—´è¿œå¤§äºå®é™…éœ€æ±‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"æœ€ç»ˆéªŒè¯\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "print(f\"\\nå›¾åƒåµŒå…¥:\")\n",
                "print(f\"  âœ“ Movie ID æ•°é‡: {df_image['movie_id'].nunique()}\")\n",
                "print(f\"  âœ“ å”¯ä¸€åµŒå…¥å‘é‡æ•°é‡: {len(df_image[image_emb_cols].drop_duplicates())}\")\n",
                "print(f\"  âœ“ æ˜¯å¦ä¸€ä¸€å¯¹åº”: {df_image['movie_id'].nunique() == len(df_image[image_emb_cols].drop_duplicates())}\")\n",
                "\n",
                "print(f\"\\næ–‡æœ¬åµŒå…¥:\")\n",
                "print(f\"  âœ“ Movie ID æ•°é‡: {df_text['movie_id'].nunique()}\")\n",
                "print(f\"  âœ“ å”¯ä¸€åµŒå…¥å‘é‡æ•°é‡: {len(df_text[text_emb_cols].drop_duplicates())}\")\n",
                "print(f\"  âœ“ æ˜¯å¦ä¸€ä¸€å¯¹åº”: {df_text['movie_id'].nunique() == len(df_text[text_emb_cols].drop_duplicates())}\")\n",
                "\n",
                "print(\"\\nğŸ‰ åˆ†æå®Œæˆï¼åµŒå…¥æ•°æ®ç»“æ„æ­£å¸¸ï¼Œå¤šæ ·æ€§å……è¶³ï¼\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}